{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Sleep Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cnn_utilities as cnn_utils\n",
    "from cnn_utilities import *\n",
    "import utilities as utils\n",
    "from utilities import *\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 160\n",
    "colors = sns.color_palette(\"viridis\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_dir = \"../data/preprocessed\"\n",
    "data_source_type = \"gdansk\" # [\"gdansk\", \"physionet\"]\n",
    "splice_type = \"constant\" # [\"complete\", \"constant\", \"random\"]\n",
    "label_type = \"regression\" # [\"classification\", \"regression\"]\n",
    "simulation = True # [True, False]\n",
    "class_weights = False # [True, False]\n",
    "sampling = \"oversample\" # [\"none\", \"undersample\", \"oversample\"]\n",
    "\n",
    "batch_size = 8\n",
    "no_workers = 1\n",
    "double_precision = False # Only for regression\n",
    "\n",
    "epochs = 120\n",
    "learning_rate = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto adjustment\n",
    "data_type = \"simulated\" if simulation else \"original\"\n",
    "class_weights_type = \"weighted_\" if class_weights else \"unweighted_\"\n",
    "\n",
    "if label_type == \"regression\":\n",
    "    class_weights_type = \"\"\n",
    "\n",
    "if simulation:\n",
    "    N = 96\n",
    "    simulated = 100\n",
    "    data_source_type = \"gdansk\"\n",
    "    splice_type = \"constant\"\n",
    "    epochs //= 10\n",
    "else:\n",
    "    N = 48\n",
    "    simulated = None\n",
    "\n",
    "read_path = f\"{data_dir}/{data_type}_{data_source_type}_{splice_type}_deep_{label_type}_seconds_\"\n",
    "y_name = \"label\" if label_type == \"classification\" else \"age\"\n",
    "no_classes = 7 if data_source_type == \"gdansk\" else 6\n",
    "N = 48 if data_source_type == \"gdansk\" else 240\n",
    "pad_length = 27_000 if data_source_type == \"gdansk\" else 135_000\n",
    "side_arm_mlp = 128 if data_source_type == \"gdansk\" else 64\n",
    "channels = 128 if data_source_type == \"gdansk\" else 64\n",
    "lstm_hidden = 256 if data_source_type == \"gdansk\" else 128\n",
    "side_arm_mlp = 32 if data_source_type == \"physionet\" and splice_type==\"complete\" else side_arm_mlp\n",
    "\n",
    "if splice_type == \"constant\":\n",
    "    pad_length //= N\n",
    "    batch_size *= 64\n",
    "    \n",
    "if data_source_type == \"physionet\" and splice_type == \"complete\":\n",
    "    batch_size //= 8\n",
    "    \n",
    "if label_type == \"classification\" and splice_type == \"complete\":\n",
    "    batch_size //= 8\n",
    "    \n",
    "if label_type == \"classification\" or data_source_type == \"physionet\":\n",
    "    epochs //= 3\n",
    "\n",
    "batch_size = max(1, batch_size)\n",
    "\n",
    "classification = label_type==\"classification\"\n",
    "complete = splice_type == \"complete\"\n",
    "truncate = None\n",
    "\n",
    "if simulation:\n",
    "    pad_length = 200\n",
    "    truncate = pad_length\n",
    "\n",
    "if sampling == \"oversample\":\n",
    "    sample_addon = \"oversample\"\n",
    "elif sampling == \"undersample\":\n",
    "    sample_addon = \"undersample\"\n",
    "else:\n",
    "    sample_addon = \"none\"\n",
    "\n",
    "relative_folder_dir = \"../report/img/learning/\"\n",
    "basic_path = f\"{data_type}_{data_source_type}_sleepnet_{label_type}_{splice_type}_{sample_addon}_{class_weights_type}\"\n",
    "model_save_path = \"models/\" + basic_path + f\"model.save\"\n",
    "loss_save_path = relative_folder_dir + basic_path + \"loss.png\"\n",
    "accuracy_save_path = relative_folder_dir + basic_path + \"accuracy.png\"\n",
    "error_distribution_save_path = relative_folder_dir + basic_path + \"error_distribution.png\"\n",
    "error_distribution_unbiased_save_path = relative_folder_dir + basic_path + \"error_distribution_unbiased.png\"\n",
    "\n",
    "metrics_save_path = f\"../report/results/{basic_path}metrics.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../report/results/simulated_gdansk_sleepnet_regression_constant_oversample_metrics.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/simulated_gdansk_sleepnet_regression_constant_oversample_model.save'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating oversampled dataset '../data/preprocessed/simulated_gdansk_constant_deep_regression_seconds_train_oversample.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flennic/anaconda3/envs/master-thesis/lib/python3.8/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 27s, sys: 13.5 s, total: 8min 40s\n",
      "Wall time: 9min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if sampling == \"undersample\":\n",
    "    if not os.path.exists(read_path + \"train_undersample.csv\"):\n",
    "        print(f\"Creating undersampled dataset '{read_path}train_undersample.csv'.\")\n",
    "        train = pd.read_csv(read_path + \"train.csv\", index_col=0)\n",
    "        train_undersampled = utils.undersample_df(train, y_name)\n",
    "        train_undersampled.to_csv(read_path + \"train_undersample.csv\", index_label=None)\n",
    "        del train, train_undersampled\n",
    "    else:\n",
    "        print(f\"Undersampled dataset '{read_path}train_undersample.csv' does already exist.\")\n",
    "    sample_addon = \"_undersample\"\n",
    "elif sampling == \"oversample\":\n",
    "    if not os.path.exists(read_path + \"train_oversample.csv\"):\n",
    "        print(f\"Creating oversampled dataset '{read_path}train_oversample.csv'.\")\n",
    "        train = pd.read_csv(read_path + \"train.csv\", index_col=0)\n",
    "        train_oversampled = utils.oversample_df(train, y_name)\n",
    "        train_oversampled.to_csv(read_path + \"train_oversample.csv\", index_label=None)\n",
    "        del train, train_oversampled\n",
    "    else:\n",
    "        print(f\"Oversampled dataset '{read_path}train_oversample.csv' does already exist.\")\n",
    "    sample_addon = \"_oversample\"\n",
    "else:\n",
    "    print(f\"Taking dataset '{read_path}train.csv' without sampling.\")\n",
    "    sample_addon = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 48.2 s, total: 4min 58s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, train_data_set = cnn_utils.path_to_DataLoader(read_path + f\"train{sample_addon}.csv\", index=True, classification=classification, batch_size=batch_size)\n",
    "val, val_data_set = cnn_utils.path_to_DataLoader(read_path + \"val.csv\", index=True, classification=classification, batch_size=batch_size, truncate=truncate)\n",
    "test, test_data_set = cnn_utils.path_to_DataLoader(read_path + \"test.csv\", index=True, classification=classification, batch_size=batch_size, truncate=truncate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_type == \"classification\":\n",
    "    class_weights = torch.tensor(utils.class_weights_from_path(read_path + f\"train{sample_addon}.csv\", no_classes, y_name), dtype=torch.float).cuda() if class_weights else None\n",
    "    print(class_weights)\n",
    "    model = DeepSleepNet(no_classes,\n",
    "                         data_length=pad_length,\n",
    "                         batch_size=batch_size,\n",
    "                         complete=complete,\n",
    "                         side_arm_mlp=side_arm_mlp,\n",
    "                         channels=channels,\n",
    "                         lstm_hidden=lstm_hidden).cuda()\n",
    "elif label_type == \"regression\":\n",
    "    model = DeepSleepNet(no_classes,\n",
    "                         data_length=pad_length,\n",
    "                         batch_size=batch_size,\n",
    "                         classification=classification,\n",
    "                         side_arm_mlp=side_arm_mlp,\n",
    "                         channels=channels,\n",
    "                         lstm_hidden=lstm_hidden).cuda()\n",
    "else:\n",
    "    print(\"label_type not supported.\")\n",
    "    \n",
    "if double_precision:\n",
    "    model.double()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "if classification:\n",
    "    criterion = torch.nn.NLLLoss(weight = class_weights)\n",
    "else:\n",
    "    criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/simulated_gdansk_sleepnet_regression_constant_oversample_model.save'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Training Mean Absolute Error: 36.0236291299416\n",
      "Training Loss: 1297.7018556915768\n",
      "Training Accuracy: 0.10906684027777777\n",
      "Validation Mean Absolute Error: 19.778156686265458\n",
      "Validation Loss: 391.17548190646704\n",
      "Validation Accuracy: 0.13910011574074074\n",
      "Model saved. Epoch 1.\n",
      "\n",
      "Epoch: 2\n",
      "Training Mean Absolute Error: 17.244543423959268\n",
      "Training Loss: 297.3742779008169\n",
      "Training Accuracy: 0.19668712797619048\n",
      "Validation Mean Absolute Error: 21.432904168672888\n",
      "Validation Loss: 459.36938110351565\n",
      "Validation Accuracy: 0.15694733796296295\n",
      "\n",
      "Epoch: 3\n",
      "Training Mean Absolute Error: 16.790471855818115\n",
      "Training Loss: 281.91994514102026\n",
      "Training Accuracy: 0.20469308035714287\n",
      "Validation Mean Absolute Error: 19.29045579076668\n",
      "Validation Loss: 372.12168461552375\n",
      "Validation Accuracy: 0.1533101851851852\n",
      "Model saved. Epoch 3.\n",
      "\n",
      "Epoch: 4\n",
      "Training Mean Absolute Error: 16.50968257578262\n",
      "Training Loss: 272.5696187531002\n",
      "Training Accuracy: 0.2127064732142857\n",
      "Validation Mean Absolute Error: 19.6797197927429\n",
      "Validation Loss: 387.29137112087676\n",
      "Validation Accuracy: 0.13597222222222222\n",
      "\n",
      "Epoch: 5\n",
      "Training Mean Absolute Error: 16.296649196242242\n",
      "Training Loss: 265.5807750253829\n",
      "Training Accuracy: 0.21974020337301586\n",
      "Validation Mean Absolute Error: 20.582301543712237\n",
      "Validation Loss: 423.63113683629916\n",
      "Validation Accuracy: 0.13758391203703704\n",
      "\n",
      "Epoch: 6\n",
      "1079296/1612800 (66.92%)\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_loss_storage = []\n",
    "training_accuracy_storage = []\n",
    "validation_loss_storage = []\n",
    "validation_accuracy_storage = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    print(\"\\nEpoch: {}\".format(i+1))\n",
    "    \n",
    "    training_loss = 0\n",
    "    training_accuracy = 0\n",
    "    training_processed_data = 0\n",
    "    training_processed_batches = 0\n",
    "    \n",
    "    for x, y in train:\n",
    "        \n",
    "        # Initialize hidden states in each batch\n",
    "        model.init_hidden(x.shape[0])\n",
    "        \n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        # Reset Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward, Loss, Backwards, Update\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_processed_data += x.shape[0]\n",
    "        training_processed_batches += 1\n",
    "\n",
    "        # Calculate Metrics\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "        if classification:\n",
    "            training_accuracy += torch.sum(torch.exp(output).topk(1)[1].view(-1) == y).item()\n",
    "        else:\n",
    "            training_accuracy += torch.sum(torch.abs(output - y) < 5).cpu().numpy()\n",
    "        \n",
    "        print(f\"{training_processed_data}/{len(train_data_set)} ({round(training_processed_data/len(train_data_set)*100, 2)}%)\", end=\"\\r\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Training Mean Absolute Error: {}\".format(np.sqrt(training_loss/training_processed_batches)))\n",
    "        print(\"Training Loss: {}\".format(training_loss/training_processed_batches))\n",
    "        print(\"Training Accuracy: {}\".format(training_accuracy/training_processed_data))\n",
    "        \n",
    "        training_loss_storage.append(training_loss/training_processed_batches)\n",
    "        training_accuracy_storage.append(training_accuracy/training_processed_data)\n",
    "        \n",
    "        validation_loss = 0\n",
    "        validation_accuracy = 0\n",
    "        validation_processed_data = 0\n",
    "        validation_processed_batches = 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val:\n",
    "                \n",
    "                model.init_hidden(x.shape[0])\n",
    "                \n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "                output_validation = model(x)\n",
    "                loss_val = criterion(output_validation, y)\n",
    "                \n",
    "                validation_processed_data += x.shape[0]\n",
    "                validation_processed_batches += 1\n",
    "                \n",
    "                validation_loss += loss_val.item()\n",
    "                \n",
    "                if classification:\n",
    "                    validation_accuracy += torch.sum(\n",
    "                        torch.exp(output_validation).topk(1, dim=1)[1].view(-1) == y).item()\n",
    "                else:\n",
    "                    validation_accuracy += torch.sum(torch.abs(output_validation - y) < 5).cpu().numpy()\n",
    "                \n",
    "            else:\n",
    "                print(\"Validation Mean Absolute Error: {}\".format(np.sqrt(validation_loss/validation_processed_batches)))\n",
    "                print(\"Validation Loss: {}\".format(validation_loss/validation_processed_batches))\n",
    "                print(\"Validation Accuracy: {}\".format(validation_accuracy/validation_processed_data))\n",
    "                \n",
    "                # Save model if the validation accuracy was the lowest so far.\n",
    "                #if all((validation_accuracy/validation_processed_data) >= np.array(validation_accuracy_storage)) or len(validation_accuracy_storage) == 0:\n",
    "                #    torch.save(model.state_dict(), model_save_path)\n",
    "                #    print(f\"Model saved. Epoch {i+1}.\")\n",
    "                    \n",
    "                # Save model if the validation loss was the lowest so far.\n",
    "                if all((validation_loss/validation_processed_batches) <= np.array(validation_loss_storage)) or len(validation_loss_storage) == 0:\n",
    "                    torch.save(model.state_dict(), model_save_path)\n",
    "                    print(f\"Model saved. Epoch {i+1}.\")\n",
    "                \n",
    "                validation_loss_storage.append(validation_loss/validation_processed_batches)\n",
    "                validation_accuracy_storage.append(validation_accuracy/validation_processed_data)\n",
    "                    \n",
    "                model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(range(len(training_loss_storage)), training_loss_storage, label=\"Training Loss\", color=colors[9]);\n",
    "sns.lineplot(range(len(validation_loss_storage)), validation_loss_storage, label=\"Validation Loss\", color=colors[0]);\n",
    "plt.legend()\n",
    "plt.ylabel('Loss');\n",
    "plt.xlabel('Epoch');\n",
    "plt.title(f'Loss During Training ({label_type} | {splice_type})');\n",
    "plt.savefig(loss_save_path);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(range(len(training_accuracy_storage)), training_accuracy_storage, label=\"Training Accuracy\", color=colors[9]);\n",
    "sns.lineplot(range(len(validation_accuracy_storage)), validation_accuracy_storage, label=\"Validation Accuracy\", color=colors[0]);\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy');\n",
    "plt.xlabel('Epoch');\n",
    "plt.title(f'Accuracy During Training ({label_type} | {splice_type})');\n",
    "plt.savefig(accuracy_save_path);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, val, test, train_data_set, val_data_set, test_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result = \"\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "if label_type == \"classification\" and splice_type == \"complete\":\n",
    "    train_res, train_error_distribution = cnn_utils.evaluate_classification_complete(model, read_path + \"train.csv\", batch_size=batch_size, no_classes=no_classes)\n",
    "    val_res, val_error_distribution = cnn_utils.evaluate_classification_complete(model, read_path + \"val.csv\", batch_size=batch_size, no_classes=no_classes)\n",
    "    test_res, test_error_distribution = cnn_utils.evaluate_classification_complete(model, read_path + \"test.csv\", batch_size=batch_size, no_classes=no_classes)\n",
    "\n",
    "elif label_type == \"regression\" and splice_type == \"complete\":\n",
    "    train_res, train_error_distribution = cnn_utils.evaluate_regression_complete(model, read_path + \"train.csv\", batch_size=batch_size, no_classes=no_classes)\n",
    "    val_res, val_error_distribution = cnn_utils.evaluate_regression_complete(model, read_path + \"val.csv\", batch_size=batch_size, no_classes=no_classes)\n",
    "    test_res, test_error_distribution = cnn_utils.evaluate_regression_complete(model, read_path + \"test.csv\", batch_size=batch_size, no_classes=no_classes)\n",
    "    \n",
    "    train_res_unbiased, _ = cnn_utils.evaluate_regression_complete(model,read_path + \"train.csv\", batch_size=batch_size, no_classes=no_classes,\n",
    "                                                            bias=np.mean(val_error_distribution))\n",
    "    val_res_unbiased, _ = cnn_utils.evaluate_regression_complete(model,read_path + \"val.csv\", batch_size=batch_size, no_classes=no_classes,\n",
    "                                                            bias=np.mean(val_error_distribution))\n",
    "    test_res_unbiased, test_unbiased_error_distribution = cnn_utils.evaluate_regression_complete(model,read_path + \"test.csv\", batch_size=batch_size,\n",
    "                                                            no_classes=no_classes,\n",
    "                                                            bias=np.mean(val_error_distribution))\n",
    "\n",
    "elif label_type == \"classification\" and splice_type == \"constant\":\n",
    "    train_res, train_error_distribution = cnn_utils.evaluate_classification_constant(model, read_path + \"train.csv\", batch_size=batch_size, N=N, no_classes=no_classes, simulated=simulated)\n",
    "    val_res, val_error_distribution = cnn_utils.evaluate_classification_constant(model, read_path + \"val.csv\", batch_size=batch_size, N=N, no_classes=no_classes, simulated=simulated)\n",
    "    test_res, test_error_distribution = cnn_utils.evaluate_classification_constant(model, read_path + \"test.csv\", batch_size=batch_size, N=N, no_classes=no_classes, simulated=simulated)\n",
    "\n",
    "elif label_type == \"regression\" and splice_type == \"constant\":\n",
    "    train_res, train_error_distribution = cnn_utils.evaluate_regression_constant(model, read_path + \"train.csv\", batch_size=batch_size, N=N, no_classes=no_classes, simulated=simulated)\n",
    "    val_res, val_error_distribution = cnn_utils.evaluate_regression_constant(model, read_path + \"val.csv\", batch_size=batch_size, N=N, no_classes=no_classes, simulated=simulated)\n",
    "    test_res, test_error_distribution = cnn_utils.evaluate_regression_constant(model, read_path + \"test.csv\", batch_size=batch_size, N=N, no_classes=no_classes, simulated=simulated)\n",
    "    \n",
    "    train_res_unbiased, _ = cnn_utils.evaluate_regression_constant(model, read_path + \"train.csv\", batch_size=batch_size, N=N, no_classes=no_classes,\n",
    "                                                            bias=np.mean(val_error_distribution), simulated=simulated)\n",
    "    val_res_unbiased, _ = cnn_utils.evaluate_regression_constant(model, read_path + \"val.csv\", batch_size=batch_size, N=N, no_classes=no_classes,\n",
    "                                                            bias=np.mean(val_error_distribution), simulated=simulated)\n",
    "    test_res_unbiased, test_unbiased_error_distribution = cnn_utils.evaluate_regression_constant(model, read_path + \"test.csv\", batch_size=batch_size, N=N,\n",
    "                                                            no_classes=no_classes,\n",
    "                                                            bias=np.mean(val_error_distribution), simulated=simulated)\n",
    "    \n",
    "else:\n",
    "    print(\"label_type and splice_type combination not supported.\")\n",
    "\n",
    "result += f\"Training Accuracy: {train_res}\\n\"\n",
    "result += f\"Validation Accuracy: {val_res}\\n\"\n",
    "result += f\"Test Accuracy: {test_res}\\n\\n\"\n",
    "result += f\"Estimated Bias: {np.mean(val_error_distribution)}\\n\\n\"\n",
    "\n",
    "if not classification:\n",
    "    result += f\"Unbiased Training Accuracy: {train_res_unbiased}\\n\"\n",
    "    result += f\"Unbiased Validation Accuracy: {val_res_unbiased}\\n\"\n",
    "    result += f\"Unbiased Test Accuracy: {test_res_unbiased}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = len(np.unique(test_error_distribution)) if classification else None\n",
    "sns.set(style=\"white\")\n",
    "sns.distplot(test_error_distribution, color=sns.color_palette(\"viridis\", 10)[5], label=\"Error Density\", bins=bins)\n",
    "plt.ylabel('Density');\n",
    "plt.xlabel('Error');\n",
    "plt.title(f'Error Distribution ({label_type} | {splice_type})');\n",
    "plt.legend();\n",
    "plt.savefig(error_distribution_save_path);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not classification:\n",
    "    sns.set(style=\"white\")\n",
    "    sns.distplot(test_unbiased_error_distribution, color=sns.color_palette(\"viridis\", 10)[5], label=\"Error Density\")\n",
    "    plt.ylabel('Density');\n",
    "    plt.xlabel('Error');\n",
    "    plt.title(f'Unbiased Error Distribution ({label_type} | {splice_type})');\n",
    "    plt.legend();\n",
    "    plt.savefig(error_distribution_unbiased_save_path);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not classification:\n",
    "    unbiased_mean = np.mean(test_unbiased_error_distribution)\n",
    "    unbiased_std = np.std(test_unbiased_error_distribution)\n",
    "    ci = np.percentile(test_unbiased_error_distribution, [2.5, 97.5])\n",
    "    \n",
    "    result += \"\\n\\n\"\n",
    "    result += f\"# Estimates\\n\"\n",
    "    result += f\"Unbiased Mean:\\t\\t\\t{unbiased_mean}\\n\"\n",
    "    result += f\"Standard Deviation:\\t\\t{unbiased_std}\\n\"\n",
    "    result += f\"95% Prediction Interval:\\t{unbiased_mean - 1.96 * unbiased_std} to {unbiased_mean + 1.96 * unbiased_std}\\n\\n\"\n",
    "    result += f\"# Estimate from percentiles\\n\"\n",
    "    result += f\"95% Prediction Interval:\\t{ci[0]+unbiased_mean} to {ci[1]+unbiased_mean}\\n\\n\"\n",
    "    result += f\"# Pure PI\\n\"\n",
    "    result += f\"95% Prediction Interval:\\t{- 1.96 * unbiased_std} to {1.96 * unbiased_std}\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result += f\"\\nEpochs: {epochs}\\n\"\n",
    "result += f\"Learning Rate: {learning_rate}\\n\"\n",
    "result += f\"Batch Size: {batch_size}\\n\"\n",
    "result += f\"Side-Arm MLP: {side_arm_mlp}\\n\"\n",
    "result += f\"LSTM Hidden: {lstm_hidden}\\n\"\n",
    "result += f\"Channels: {channels}\\n\"\n",
    "result += f\"Sampling: {sampling}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metrics_save_path, \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
