{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 160\n",
    "colors = sns.color_palette(\"viridis\", 10)\n",
    "\n",
    "import utilities as utils\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pamateters\n",
    "data_dir = \"../data/preprocessed\"\n",
    "data_source_type = \"gdansk\" # [\"gdansk\", \"physionet\"]\n",
    "splice_type = \"constant\" # [\"complete\", \"constant\", \"random\"]\n",
    "label_type = \"classification\" # [\"classification\", \"regression\"]\n",
    "simulation = True # [True, False]\n",
    "\n",
    "max_size_cv = 80_000\n",
    "max_size_fit = 160_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto adjustment\n",
    "\n",
    "data_type = \"simulated\" if simulation else \"original\"\n",
    "\n",
    "if simulation:\n",
    "    splice_type = \"constant\"\n",
    "    data_source_type = \"gdansk\"\n",
    "    N = 96\n",
    "    simulated = 100\n",
    "else:\n",
    "    N = 48\n",
    "    simulated = None\n",
    "    \n",
    "read_path = f\"{data_dir}/{data_type}_{data_source_type}_{splice_type}_features_{label_type}_milliseconds_\"\n",
    "y_name = \"label\" if label_type == \"classification\" else \"age\"\n",
    "\n",
    "if label_type != \"classification\":\n",
    "    raise Exception(\"label_type can only be classification.\")\n",
    "    \n",
    "no_classes = 7 if data_source_type == \"gdansk\" else 6\n",
    "classification = label_type==\"classification\"\n",
    "\n",
    "relative_folder_dir = \"../report/img/learning/\"\n",
    "basic_path = f\"{data_type}_{data_source_type}_naive_bayes_{label_type}_{splice_type}_\"\n",
    "error_distribution_save_path = relative_folder_dir + basic_path + \"error_distribution.png\"\n",
    "error_distribution_unbiased_save_path = relative_folder_dir + basic_path + \"error_distribution_unbiased.png\"\n",
    "\n",
    "metrics_save_path = f\"../report/results/{basic_path}metrics.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing samples for cross validation from 1179400 to 80000.\n",
      "Reducing samples for fitting from 1179400 to 160000.\n",
      "CPU times: user 8.59 s, sys: 572 ms, total: 9.16 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(read_path + \"train.csv\", index_col=0)\n",
    "val = pd.read_csv(read_path + \"val.csv\", index_col=0)\n",
    "test = pd.read_csv(read_path + \"test.csv\", index_col=0)\n",
    "\n",
    "train = pd.concat([train, val])\n",
    "del val\n",
    "\n",
    "if train.shape[0] > max_size_cv:\n",
    "    print(f\"Reducing samples for cross validation from {train.shape[0]} to {max_size_cv}.\")\n",
    "    train_cv = train.sample(max_size_cv)\n",
    "else:\n",
    "    print(f\"Keeping {train.shape[0]} samples for cross validation.\")\n",
    "    train_cv = train\n",
    "    \n",
    "if train.shape[0] > max_size_fit:\n",
    "    print(f\"Reducing samples for fitting from {train.shape[0]} to {max_size_fit}.\")\n",
    "    train_fit = train.sample(max_size_fit)\n",
    "else:\n",
    "    print(f\"Keeping {train.shape[0]} samples for fitting.\")\n",
    "    train_fit = train\n",
    "    \n",
    "# Train CV\n",
    "X_train_cv = train_cv.loc[:, train_cv.columns != y_name]\n",
    "X_train_cv = X_train_cv.drop(columns=['tinn']) # Is all 'None'\n",
    "Y_train_cv = train_cv[y_name]\n",
    "\n",
    "# Train Fit\n",
    "X_train_fit = train_fit.loc[:, train_fit.columns != y_name]\n",
    "X_train_fit = X_train_fit.drop(columns=['tinn']) # Is all 'None'\n",
    "Y_train_fit = train_fit[y_name]\n",
    "\n",
    "# Train Eval\n",
    "X_train = train.loc[:, train.columns != y_name]\n",
    "X_train = X_train.drop(columns=['tinn']) # Is all 'None'\n",
    "Y_train = train[y_name]\n",
    "#Y_train = Y_train_fit\n",
    "\n",
    "# Test\n",
    "X_test = test.loc[:, test.columns != y_name]\n",
    "X_test = X_test.drop(columns=['tinn']) # Is all 'None'\n",
    "Y_test = test[y_name]\n",
    "#Y_test = Y_test_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13648362 0.12664921 0.21875686 0.14967612 0.14967612 0.11513576\n",
      " 0.1036223 ]\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:    1.3s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    1.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    1.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c16869846a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "class_weights = utils.class_weights_from_path(read_path + f\"train.csv\", no_classes, y_name, inverse=False)\n",
    "print(class_weights)\n",
    "\n",
    "parameters = {\n",
    "                'classifier__alpha': (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)\n",
    "             }\n",
    "\n",
    "pipe = pipeline.Pipeline(steps = [\n",
    "    ('classifier', MultinomialNB(class_prior=class_weights))\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipe, parameters, cv = 3, n_jobs = -1, verbose = 10)\n",
    "clf.fit(X_train_cv, Y_train_cv)\n",
    "\n",
    "parameter = clf.best_params_\n",
    "\n",
    "print(f\"Best set of parameters is: {parameter}. Fitting now.\")\n",
    "\n",
    "clf = MultinomialNB(class_prior=class_weights, alpha=parameter['classifier__alpha'])\n",
    "\n",
    "clf.fit(X_train_fit, Y_train_fit)\n",
    "\n",
    "print(\"Fit is completed. Predicting now.\")\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"\"\n",
    "\n",
    "if label_type == \"classification\" and splice_type == \"complete\":\n",
    "    train_error_distribution = Y_train_pred - Y_train\n",
    "    test_error_distribution = Y_test_pred - Y_test\n",
    "    \n",
    "    result += f\"Accuracy Train: {sklearn.metrics.accuracy_score(Y_train, Y_train_pred)}\\n\"\n",
    "    result += f\"Accuracy Test: {sklearn.metrics.accuracy_score(Y_test, Y_test_pred)}\\n\"\n",
    "    \n",
    "elif label_type == \"classification\" and splice_type == \"constant\":\n",
    "    train_error_distribution = Y_train_pred - Y_train\n",
    "    test_error_distribution = Y_test_pred - Y_test\n",
    "    \n",
    "    result += f\"Accuracy Train: {utils.accuracy_score_from_label_chunks(Y_train, Y_train_pred, N=N, simulated=simulated)}\\n\"\n",
    "    result += f\"Accuracy Test: {utils.accuracy_score_from_label_chunks(Y_test, Y_test_pred, N=N, simulated=simulated)}\\n\"\n",
    "    \n",
    "else:\n",
    "    print(\"label_type and splice_type combination not supported.\")\n",
    "\n",
    "result += f\"\\nMax Size CV: Taken -> {min(train.shape[0], max_size_cv)}, cap -> {max_size_cv}, available -> {train.shape[0]}.\\n\"\n",
    "result += f\"Max Size Fit: Taken -> {min(train.shape[0], max_size_fit)}, cap -> {max_size_fit}, available -> {train.shape[0]}.\\n\"\n",
    "result += f\"Best Parameters: {parameter}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = len(np.unique(test_error_distribution)) if classification else None\n",
    "sns.set(style=\"white\")\n",
    "sns.distplot(test_error_distribution, color=sns.color_palette(\"viridis\", 10)[5], label=\"Error Density\", bins=bins)\n",
    "plt.ylabel('Density');\n",
    "plt.xlabel('Error');\n",
    "plt.title(f'Naive Bayes Error Distribution ({label_type} | {splice_type})');\n",
    "plt.legend();\n",
    "plt.savefig(error_distribution_save_path);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metrics_save_path, \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
