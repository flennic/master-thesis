{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hrvanalysis as hrv\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/age_decades/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_recording_to_dict(filepath, rawPythonic=True):\n",
    "    \n",
    "    recording = {}\n",
    "    \n",
    "    with open(filepath) as raw_recording:\n",
    "        \n",
    "        recording[\"Gender\"] = filepath.split(\"/\")[-1][0:1]\n",
    "        recording[\"AgeDecade\"] = filepath.split(\"/\")[-1][1:3]\n",
    "        recording[\"RecordingStartTime\"] = datetime.strptime(filepath.split(\"/\")[-1][4:9], '%H.%M').time()\n",
    "        \n",
    "        series = {\"ContractionNo\": [], \"ContractionNoNorm\": [], \"RrInterval\": []}\n",
    "        \n",
    "        first_index = None\n",
    "        previous_ContractionNo = None\n",
    "        \n",
    "        for line in raw_recording:\n",
    "            \n",
    "            # Handling shifted indexes\n",
    "            if first_index is None:\n",
    "                first_index = int(line.split()[1])\n",
    "            \n",
    "            # Fill missing data with None's\n",
    "            if previous_ContractionNo is not None:\n",
    "                diff = abs(previous_ContractionNo - int(line.split()[1]))\n",
    "                \n",
    "                if diff > 1:\n",
    "                    \n",
    "                    filling_indexes = np.array(range(previous_ContractionNo+1, int(line.split()[1])))\n",
    "                    \n",
    "                    series[\"ContractionNo\"].extend(filling_indexes)\n",
    "                    series[\"ContractionNoNorm\"].extend(filling_indexes - first_index)\n",
    "                    series[\"RrInterval\"].extend([math.nan]*(diff-1))\n",
    "          \n",
    "            series[\"ContractionNo\"].append(int(line.split()[1]))\n",
    "            series[\"ContractionNoNorm\"].append(int(line.split()[1]) - first_index)\n",
    "            series[\"RrInterval\"].append(int(line.split()[0]))\n",
    "            \n",
    "            previous_ContractionNo = int(line.split()[1])\n",
    "            \n",
    "        if rawPythonic:\n",
    "            recording[\"Series\"] = series\n",
    "            recording[\"RecordingStartTime\"] = str(recording[\"RecordingStartTime\"])\n",
    "        else:\n",
    "            recording[\"Series\"] = pd.DataFrame(series)\n",
    "            \n",
    "        return recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "recordings = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    recordings.append(raw_recording_to_dict(data_dir + filename, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings[0][\"Series\"][\"RrInterval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#interpolated_example = hrv.interpolate_nan_values(recordings[0][\"Series\"][\"RrInterval\"][:10_000])\n",
    "print(len(recordings[0][\"Series\"][\"RrInterval\"]))\n",
    "interpolated_example = hrv.preprocessing.get_nn_intervals(recordings[0][\"Series\"][\"RrInterval\"], interpolation_method='linear')\n",
    "#interpolated_example = pd.Series(interpolated_example).dropna().tolist()\n",
    "#, interpolation_method=\"cubic\")\n",
    "np.mean(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hrv.get_time_domain_features(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv.get_geometrical_features(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv.get_frequency_domain_features(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pd.Series([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv.get_frequency_domain_features(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv.get_frequency_domain_features(pd.Series(interpolated_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv.get_csi_cvi_features(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv.get_poincare_plot_features(interpolated_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hrv.get_geometrical_features(interpolated_example)\n",
    "hrv.get_frequency_domain_features(interpolated_example)\n",
    "hrv.get_csi_cvi_features(interpolated_example)\n",
    "hrv.get_poincare_plot_features(interpolated_example)\n",
    "hrv.get_sampen(interpolated_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[value for value in hrv.get_time_domain_features(interpolated_example).values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [key for key in hrv.get_time_domain_features(interpolated_example).keys()]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [key for key in hrv.get_time_domain_features(interpolated_example).keys()]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decade_to_label(decade):\n",
    "    return(int(int(decade)/10) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, splits=[0.6, 0.2, 0.2]):\n",
    "    return np.array_split(data, (np.array(splits)[:-1].cumsum() * len(data)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,2,3,4,5,6,None]).interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordings_to_dataframe(recordings, interpolation_method='linear'):\n",
    "    \n",
    "    data_frame = pd.DataFrame()\n",
    "    column_names = []\n",
    "\n",
    "    for i, recording in enumerate(recordings):\n",
    "\n",
    "        interpolated_recording = hrv.preprocessing.get_nn_intervals(recording[\"Series\"][\"RrInterval\"],\n",
    "                                                                    interpolation_method=interpolation_method,\n",
    "                                                                    verbose=False)\n",
    "\n",
    "        #interpolated_recording = pd.Series(interpolated_example).dropna().tolist()\n",
    "\n",
    "        time_domain_features = hrv.get_time_domain_features(interpolated_recording)\n",
    "        geometrical_features = hrv.get_geometrical_features(interpolated_recording)\n",
    "        frequency_domain_features = hrv.get_frequency_domain_features(interpolated_recording)\n",
    "        csi_cvi_features = hrv.get_csi_cvi_features(interpolated_recording)\n",
    "        poincare_plot_features = hrv.get_poincare_plot_features(interpolated_recording)\n",
    "\n",
    "        feature_dictionary = {\n",
    "                                **time_domain_features,\n",
    "                                **geometrical_features,\n",
    "                                **frequency_domain_features,\n",
    "                                **csi_cvi_features,\n",
    "                                **poincare_plot_features\n",
    "                             }\n",
    "\n",
    "        if i == 0:\n",
    "            column_names = [key for key in feature_dictionary.keys()]\n",
    "\n",
    "        x = [value for value in feature_dictionary.values()]\n",
    "        y = decade_to_label(recording[\"AgeDecade\"])\n",
    "        data_frame = data_frame.append([[y]+ x], ignore_index=True)\n",
    "\n",
    "    data_frame.columns = [\"label\"] + column_names\n",
    "\n",
    "    return data_frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#train, val, test = split_data(recordings)\n",
    "train, val = split_data(recordings, splits=[0.8, 0.2])\n",
    "df_train = recordings_to_dataframe(train)\n",
    "df_val = recordings_to_dataframe(val)\n",
    "#df_test = recordings_to_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:, df_train.columns != 'label']\n",
    "X_train = X_train.drop(columns=['tinn']) # Is all 'None'.drop(columns=['B', 'C'])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.loc[:, df_val.columns != 'label']\n",
    "X_val = X_val.drop(columns=['tinn']) # Is all 'None'.drop(columns=['B', 'C'])\n",
    "X_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[['total_power', 'vlf', 'csi', 'cvi',\n",
    "       'Modified_csi', 'sd1', 'sd2', 'ratio_sd2_sd1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train[\"label\"]\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val = df_val[\"label\"]\n",
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = sklearn.linear_model.SGDClassifier(n_jobs=-1)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_val_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_val, Y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Y_train_pred).value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'classifier__alpha': (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)}\n",
    "\n",
    "nb_classifier_pipe = pipeline.Pipeline(steps = [\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "nb_classifier = GridSearchCV(nb_classifier_pipe, parameters, cv = 2, n_jobs = -1, verbose = 10)\n",
    "\n",
    "nb_classifier.fit(X_train, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_val_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_val, Y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Y_train_pred).value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a linreg\n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_val_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_val, Y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Y_train_pred).value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Create a SVM\n",
    "\n",
    "parameters = {\n",
    "                'classifier__C': (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0),\n",
    "                'classifier__kernel': ('linear', 'poly', 'rbf', 'sigmoid')\n",
    "             }\n",
    "\n",
    "svc_classifier_pipe = pipeline.Pipeline(steps = [\n",
    "    ('classifier', SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True,\n",
    "          probability=False, tol=0.001, cache_size=200, class_weight=None,\n",
    "          verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False,\n",
    "          random_state=None))\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(svc_classifier_pipe, parameters, cv = 3, n_jobs = -1, verbose = 10)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_val_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", sklearn.metrics.accuracy_score(Y_val, Y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Y_train_pred).value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Y_val_pred).value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
