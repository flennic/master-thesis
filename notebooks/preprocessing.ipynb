{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sections imports all necessary libraries, sets all parameters and the seed. Change to create different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "import utilities as utils\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_gdansk = \"../data/age_decades/\"\n",
    "input_physionet = \"/home/flennic/Downloads/physionet.org/files/crisdb/1.0.0/\"\n",
    "subdirs_physionet = [\"e/\", \"f/\", \"m/\"]\n",
    "output_dir = \"../data/preprocessed/\"\n",
    "\n",
    "data_source_type = \"physionet\" # [\"gdansk\", \"physionet\"]\n",
    "splice_type = \"constant\" # [\"complete\", \"constant\", \"random\"]\n",
    "label_type = \"regression\" # [\"classification\", \"regression\"]\n",
    "output_type = \"deep\" # [\"features\", \"deep\"]\n",
    "in_seconds = True # Will be automatically set to false for creating features, as the frequency features require milli seconds.\n",
    "\n",
    "splits_gdansk = [0.6, 0.2, 0.2]\n",
    "splits_physionet = [0.8, 0.1, 0.1]\n",
    "seed = 42\n",
    "pad_length = 27_000 if data_source_type == \"gdansk\" else 135_000 # For deep learning padding\n",
    "N = 48 if data_source_type == \"gdansk\" else 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto adjustment\n",
    "if data_source_type == \"gdansk\":\n",
    "    splits = splits_gdansk\n",
    "elif data_source_type == \"physionet\":\n",
    "    splits = splits_physionet\n",
    "else:\n",
    "    raise Exception(\"Data source not supported.\")\n",
    "    \n",
    "if output_type == \"features\":\n",
    "    in_seconds = False\n",
    "    unit = \"milliseconds\"\n",
    "else:\n",
    "    unit = \"seconds\" if in_seconds else \"milliseconds\"\n",
    "    \n",
    "if splice_type == \"constant\":\n",
    "    pad_length //= N\n",
    "    \n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to General Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads the different data sets and writes the information into a dictionary. The dictionary can hold different types of information, but they must have the entries `Recording` and `AgeDecade` to be eligable being processed further. Outlier detection and missing values do not need to be handled yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing e/ directory...\n",
      "Parsing f/ directory...\n",
      "Parsing m/ directory...\n",
      "CPU times: user 1min 57s, sys: 1min 34s, total: 3min 31s\n",
      "Wall time: 6min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if data_source_type == \"gdansk\":\n",
    "    recordings = utils.read_gdansk_to_dict(input_gdansk)    \n",
    "elif data_source_type == \"physionet\":\n",
    "    recordings = utils.read_physionet_to_dict(input_physionet, subdirs_physionet)\n",
    "else:\n",
    "    raise Exception(\"Data source not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 2.08 s, total: 3min 11s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleared_recordings = clear_data_in_recordings(recordings, in_seconds=in_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Splice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 335 µs, sys: 106 µs, total: 441 µs\n",
      "Wall time: 395 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_recordings, val_recordings, test_recordings = np.array_split(cleared_recordings, (np.array(splits)[:-1].cumsum() * len(cleared_recordings)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant\n",
      "Training:\n",
      "Validation:\n",
      "Test:%\n",
      "CPU times: user 2min 47s, sys: 3 s, total: 2min 50s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if splice_type == \"complete\":\n",
    "    print(\"complete\")\n",
    "elif splice_type == \"constant\":\n",
    "    print(\"constant\")\n",
    "    print(\"Training:\")\n",
    "    train_recordings = splice_lod_constant_by_number(train_recordings, n=N)\n",
    "    print(\"Validation:\")\n",
    "    val_recordings = splice_lod_constant_by_number(val_recordings, n=N)\n",
    "    print(\"Test:\")\n",
    "    test_recordings = splice_lod_constant_by_number(test_recordings, n=N)\n",
    "elif splice_type == \"random\":\n",
    "    raise Exception(\"Only do random if absolutely necesarry! Just adds do much overhead and is hardly comparable!\")\n",
    "    print(\"random\")\n",
    "    print(\"Training:\")\n",
    "    train_recordings = splice_lod_random(train_recordings, chunksize_in_minutes=5, data_is_seconds=True)\n",
    "    print(\"Validation:\")\n",
    "    val_recordings = splice_lod_random(val_recordings, chunksize_in_minutes=5, data_is_seconds=True)\n",
    "    print(\"Test:\")\n",
    "    test_recordings = splice_lod_random(test_recordings, chunksize_in_minutes=5, data_is_seconds=True)\n",
    "else:\n",
    "    raise Exception(\"Splice type not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as Features or Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source_type == \"physionet\":\n",
    "    del recordings, cleared_recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepening train...\n",
      "562\n",
      "Deepening val...\n",
      "562\n",
      "Deepening test...\n",
      "562\n",
      "Saving to disk...\n",
      "Saving to ../data/preprocessed/physionet_constant_deep_regression_seconds_TYPE.csv\n",
      "CPU times: user 6min 37s, sys: 44.9 s, total: 7min 22s\n",
      "Wall time: 7min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if output_type == \"features\":\n",
    "    classification = label_type == \"classification\"\n",
    "    print(\"Featuring train...\")\n",
    "    train_data_set = recordings_to_feature_dataframe(train_recordings, classification)\n",
    "    print(\"Featuring val...\")\n",
    "    val_data_set = recordings_to_feature_dataframe(val_recordings, classification)\n",
    "    print(\"Featuring test...\")\n",
    "    test_data_set = recordings_to_feature_dataframe(test_recordings, classification)\n",
    "    print(\"Saving to disk...\")\n",
    "    out_path = f\"{output_dir}original_{data_source_type}_{splice_type}_{output_type}_{label_type}_{unit}\"\n",
    "    print(f\"Saving to {out_path}_TYPE.csv\")\n",
    "    train_data_set.to_csv(out_path + \"_train.csv\")\n",
    "    val_data_set.to_csv(out_path + \"_val.csv\")\n",
    "    test_data_set.to_csv(out_path + \"_test.csv\")\n",
    "elif output_type == \"deep\":\n",
    "    classification = label_type == \"classification\"\n",
    "    print(\"Deepening train...\")\n",
    "    train_data_set = recordings_to_deep_dataframe(train_recordings,\n",
    "                                                  pad_length,\n",
    "                                                  classification,\n",
    "                                                  data_source_type == \"gdansk\")\n",
    "    print(\"Deepening val...\")\n",
    "    val_data_set = recordings_to_deep_dataframe(val_recordings,\n",
    "                                                pad_length,\n",
    "                                                classification,\n",
    "                                                data_source_type == \"gdansk\")\n",
    "    print(\"Deepening test...\")\n",
    "    test_data_set = recordings_to_deep_dataframe(test_recordings,\n",
    "                                                 pad_length,\n",
    "                                                 classification,\n",
    "                                                 data_source_type == \"gdansk\")\n",
    "    print(\"Saving to disk...\")\n",
    "    out_path = f\"{output_dir}original_{data_source_type}_{splice_type}_{output_type}_{label_type}_{unit}\"\n",
    "    print(f\"Saving to {out_path}_TYPE.csv\")\n",
    "    train_data_set.to_csv(out_path + \"_train.csv\")\n",
    "    val_data_set.to_csv(out_path + \"_val.csv\")\n",
    "    test_data_set.to_csv(out_path + \"_test.csv\")\n",
    "else:\n",
    "    raise Exception(\"Output type not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>rr1</th>\n",
       "      <th>rr2</th>\n",
       "      <th>rr3</th>\n",
       "      <th>rr4</th>\n",
       "      <th>rr5</th>\n",
       "      <th>rr6</th>\n",
       "      <th>rr7</th>\n",
       "      <th>rr8</th>\n",
       "      <th>rr9</th>\n",
       "      <th>...</th>\n",
       "      <th>rr553</th>\n",
       "      <th>rr554</th>\n",
       "      <th>rr555</th>\n",
       "      <th>rr556</th>\n",
       "      <th>rr557</th>\n",
       "      <th>rr558</th>\n",
       "      <th>rr559</th>\n",
       "      <th>rr560</th>\n",
       "      <th>rr561</th>\n",
       "      <th>rr562</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age    rr1    rr2    rr3    rr4    rr5    rr6    rr7    rr8    rr9  ...  \\\n",
       "0   52  0.914  0.914  0.914  0.914  0.898  0.906  0.891  0.898  0.883  ...   \n",
       "1   52  0.797  0.797  0.797  0.797  0.781  0.789  0.789  0.797  0.781  ...   \n",
       "2   52  0.742  0.727  0.734  0.734  0.734  0.719  0.734  0.734  0.727  ...   \n",
       "3   52  0.734  0.742  0.734  0.750  0.734  0.719  0.727  0.727  0.734  ...   \n",
       "4   52  0.961  0.961  0.953  0.953  0.930  0.953  0.930  0.953  0.938  ...   \n",
       "\n",
       "   rr553  rr554  rr555  rr556  rr557  rr558  rr559  rr560  rr561  rr562  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
